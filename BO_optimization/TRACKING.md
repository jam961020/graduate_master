# ì‘ì—… ì§„í–‰ ìƒí™© íŠ¸ë˜í‚¹

**í”„ë¡œì íŠ¸:** BoRisk CVaR Optimization for Welding Line Detection
**ì‹œì‘ì¼:** 2025.11.11
**í™˜ê²½:** Workstation (Linux, CUDA 12.4)

---

## ğŸ“‹ í˜„ì¬ ìš°ì„ ìˆœìœ„

1. ğŸ”´ **CRG311 Linux ë¹Œë“œ ì„¤ì¹˜** (Blocker) - AirLine ì—†ì´ëŠ” ì•„ë¬´ê²ƒë„ ëª»í•¨
2. ğŸŸ¡ **í‰ê°€ ë©”íŠ¸ë¦­ ë³€ê²½** (High) - ì§ì„  ë°©ì •ì‹ ê¸°ë°˜ìœ¼ë¡œ ì „í™˜
3. ğŸŸ¡ **í™˜ê²½ íŠ¹ì§• ê°•í™”** (High) - CLIP, PSNR/SSIM ì¶”ê°€
4. ğŸŸ¡ **RANSAC ê°€ì¤‘ì¹˜ ì¶”ê°€** (High) - 6D â†’ 9D
5. ğŸ”´ **íŒíƒ€ì§€ ê´€ì¸¡ êµ¬í˜„** (Critical) - BoRisk ì•Œê³ ë¦¬ì¦˜
6. ğŸŸ¢ **í™˜ê²½ ë³€ìˆ˜ í†µí•©** (Medium) - GPì— (x, z) ì…ë ¥

---

## ğŸ” ë°œê²¬ëœ ë¬¸ì œì  ìƒì„¸

### 1. í™˜ê²½ ë³€ìˆ˜ ë¯¸ì‚¬ìš© âŒ

**ìœ„ì¹˜:** `optimization.py`

**ë¬¸ì œ:**
- `environment_independent.py`ì— 6D í™˜ê²½ ë²¡í„° ì¶”ì¶œ ì½”ë“œ ìˆìŒ:
  - brightness, contrast, edge_density, texture_complexity, blur_level, noise_level
- **í•˜ì§€ë§Œ optimization.pyì—ì„œ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ**
- `BOUNDS`ëŠ” 6Dë§Œ ì •ì˜ (AirLine íŒŒë¼ë¯¸í„°ë§Œ)
- GP í•™ìŠµ ì‹œ: `SingleTaskGP(X, Y)` â†’ XëŠ” [N, 6]
- ì´ë¯¸ì§€ë³„ í™˜ê²½ì„ ê³ ë ¤í•˜ì§€ ì•ŠìŒ

**í˜„ì¬ êµ¬ì¡°:**
```python
# optimization.py:32-35
BOUNDS = torch.tensor([
    [-23.0, 0.5, 0.01, -23.0, 0.5, 0.01],  # 6D
    [7.0, 0.99, 0.15, 7.0, 0.99, 0.15]
])

# optimization.py:219
def objective_function(X, images_data, ...):  # X: [1, 6]
    params = {...}  # 6ê°œ íŒŒë¼ë¯¸í„°ë§Œ
    for img_data in images_data:
        score = evaluate(image, params)  # í™˜ê²½ z ì—†ìŒ!
    return cvar(scores)
```

**BoRiskì—ì„œ í•„ìš”í•œ ê²ƒ:**
```python
# ê° ì´ë¯¸ì§€ë§ˆë‹¤ í™˜ê²½ z_i ì¶”ì¶œ
env_features = extract_environment(image)  # [6D]

# GP ì…ë ¥: [x, z]
X_with_env = torch.cat([X, env_tensor], dim=-1)  # [N, 12D]
gp = SingleTaskGP(X_with_env, Y)

# í‰ê°€: (x, z) â†’ y
def objective_function(X, env_z, image):
    score = evaluate(image, X)
    return score
```

**í•´ê²° ë°©ì•ˆ:**
- BOUNDSë¥¼ 12D ë˜ëŠ” 15Dë¡œ í™•ì¥ (params 6D + env 6~9D)
- ê° ì´ë¯¸ì§€ í‰ê°€ ì‹œ í™˜ê²½ ë²¡í„° z ì¶”ì¶œ
- GPë¥¼ (x, z) â†’ yë¡œ í•™ìŠµ
- ìƒˆë¡œìš´ ì´ë¯¸ì§€ z*ì—ì„œ ìµœì  x* ì˜ˆì¸¡

---

### 2. RANSAC ê°€ì¤‘ì¹˜ ë¯¸ì—°ê²° âš ï¸

**ìœ„ì¹˜:** `full_pipeline.py:330-337`, `optimization.py:233-240`

**ë¬¸ì œ:**
- `full_pipeline.py`ì— RANSAC ê°€ì¤‘ì¹˜ë¥¼ ë°›ëŠ” ì½”ë“œëŠ” ì¡´ì¬:
```python
# full_pipeline.py:330-337
w_center = float(params.get('ransac_center_w', 0.5))
w_length = float(params.get('ransac_length_w', 0.5))
w_consensus = int(params.get('ransac_consensus_w', 5))
```

- **í•˜ì§€ë§Œ optimization.pyì—ì„œ ì´ í‚¤ë¥¼ ì „ë‹¬í•˜ì§€ ì•ŠìŒ:**
```python
# optimization.py:233-240
params = {
    'edgeThresh1': X[0, 0].item(),
    'simThresh1': X[0, 1].item(),
    'pixelRatio1': X[0, 2].item(),
    'edgeThresh2': X[0, 3].item(),
    'simThresh2': X[0, 4].item(),
    'pixelRatio2': X[0, 5].item(),
    # RANSAC ê°€ì¤‘ì¹˜ ì—†ìŒ!
}
```

**ê²°ê³¼:** RANSAC ê°€ì¤‘ì¹˜ê°€ í•­ìƒ ê¸°ë³¸ê°’(0.5, 0.5, 5)ìœ¼ë¡œ ê³ ì •

**í•´ê²° ë°©ì•ˆ:**
```python
# 1. BOUNDS í™•ì¥ (6D â†’ 9D)
BOUNDS = torch.tensor([
    [-23.0, 0.5, 0.01, -23.0, 0.5, 0.01, 0.0, 0.0, 1],
    [7.0, 0.99, 0.15, 7.0, 0.99, 0.15, 1.0, 1.0, 10]
])

# 2. paramsì— ì¶”ê°€
params = {
    'edgeThresh1': X[0, 0].item(),
    'simThresh1': X[0, 1].item(),
    'pixelRatio1': X[0, 2].item(),
    'edgeThresh2': X[0, 3].item(),
    'simThresh2': X[0, 4].item(),
    'pixelRatio2': X[0, 5].item(),
    'ransac_center_w': X[0, 6].item(),   # ì¶”ê°€
    'ransac_length_w': X[0, 7].item(),   # ì¶”ê°€
    'ransac_consensus_w': int(X[0, 8].item())  # ì¶”ê°€
}
```

---

### 3. íŒíƒ€ì§€ ê´€ì¸¡ ë¯¸êµ¬í˜„ âŒ

**ìœ„ì¹˜:** `optimization.py:292-435`

**ë¬¸ì œ:** **BoRiskì˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ì´ ì™„ì „íˆ ëˆ„ë½ë¨**

**í˜„ì¬ êµ¬í˜„:**
- ì¼ë°˜ì ì¸ Vanilla BO êµ¬ì¡°
- ëª©ì í•¨ìˆ˜: `f(x) = CVaR over all images`
- íšë“í•¨ìˆ˜: UCB ë˜ëŠ” EI
- í•œ iterationì— í•œ xë¥¼ í‰ê°€í•˜ê³  ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•œ CVaR ê³„ì‚°

**BoRiskì—ì„œ í•„ìš”í•œ ê²ƒ:**
1. **ê° ì´ë¯¸ì§€ë§ˆë‹¤ (x, z_i) â†’ y_i ê´€ì¸¡**
2. **GPëŠ” (x, z) â†’ y ë§¤í•‘ í•™ìŠµ**
3. **ìƒˆë¡œìš´ í™˜ê²½ z*ì—ì„œ ìµœì  x* ì˜ˆì¸¡ (fantasy observation)**
4. **CVaR Knowledge Gradient íšë“í•¨ìˆ˜ ì‚¬ìš©**

**êµ¬í˜„ ë°©í–¥:**
```python
# 1. ì´ë¯¸ì§€ë³„ í™˜ê²½ ì¶”ì¶œ ë° ì €ì¥
for img_data in images_data:
    img_data['env'] = extract_environment(img_data['image'])

# 2. í‰ê°€ ì‹œ (x, z, y) íŠœí”Œ ì €ì¥
observations = []
for img in sample_images:
    X_z = torch.cat([X, img['env']], dim=-1)
    y = evaluate(img['image'], X)
    observations.append((X_z, y))

# 3. GP í•™ìŠµ
X_train = torch.stack([obs[0] for obs in observations])
Y_train = torch.tensor([obs[1] for obs in observations])
gp = SingleTaskGP(X_train, Y_train)

# 4. CVaR-KG íšë“í•¨ìˆ˜
# ê° candidate xì— ëŒ€í•´:
#   - ëª¨ë“  í™˜ê²½ zì—ì„œ ì„±ëŠ¥ ì˜ˆì¸¡
#   - CVaR ê³„ì‚°
#   - Knowledge Gradient ê³„ì‚°
```

---

### 4. í‰ê°€ ë©”íŠ¸ë¦­ ë¬¸ì œ ğŸ”§

**ìœ„ì¹˜:** `optimization.py:38-117`

**ë¬¸ì œ:**
- í˜„ì¬ `simple_line_evaluation()` í•¨ìˆ˜ëŠ” **ëì  ì¢Œí‘œ ê¸°ë°˜**
- AirLineì˜ ëì  ê²€ì¶œì´ ë¶€ì‹¤í•¨
- ê°ë„ì™€ ê±°ë¦¬ ìœ ì‚¬ë„ ê³„ì‚°ì´ ëì ì— ì˜ì¡´

**í˜„ì¬ ì½”ë“œ:**
```python
# optimization.py:90-98
gt_angle = np.arctan2(gt_y2 - gt_y1, gt_x2 - gt_x1)
det_angle = np.arctan2(det_y2 - det_y1, det_x2 - det_x1)
angle_diff = abs(gt_angle - det_angle)
angle_similarity = 1.0 - (angle_diff / np.pi)
```

**ê°œì„  ë°©í–¥:**
- **ì§ì„  ë°©ì •ì‹ ê¸°ë°˜ í‰ê°€:**
  - ê¸°ìš¸ê¸°(slope): `m = (y2-y1)/(x2-x1)`
  - ì ˆí¸(intercept): `c = y1 - m*x1`
  - ì§ì„ : `y = mx + c` ë˜ëŠ” `Ax + By + C = 0`

```python
def line_equation_evaluation(detected_line, gt_line):
    """
    ì§ì„  ë°©ì •ì‹ ê¸°ë°˜ í‰ê°€

    Args:
        detected_line: [x1, y1, x2, y2]
        gt_line: [x1, y1, x2, y2]

    Returns:
        score: float [0, 1]
    """
    # 1. ì§ì„  ë°©ì •ì‹ìœ¼ë¡œ ë³€í™˜
    # Ax + By + C = 0 í˜•íƒœ
    def line_to_equation(x1, y1, x2, y2):
        A = y2 - y1
        B = x1 - x2
        C = x2*y1 - x1*y2
        norm = np.sqrt(A**2 + B**2)
        return A/norm, B/norm, C/norm

    A1, B1, C1 = line_to_equation(*gt_line)
    A2, B2, C2 = line_to_equation(*detected_line)

    # 2. ë°©í–¥ ìœ ì‚¬ë„ (ë²•ì„  ë²¡í„° ë‚´ì )
    direction_sim = abs(A1*A2 + B1*B2)

    # 3. ê±°ë¦¬ ìœ ì‚¬ë„ (ì -ì§ì„  ê±°ë¦¬)
    # GT ì§ì„ ì—ì„œ ê²€ì¶œ ì§ì„ ê¹Œì§€ í‰ê·  ê±°ë¦¬
    dist1 = abs(A1*x2 + B1*y2 + C1)  # ê²€ì¶œ ì 1
    dist2 = abs(A1*x2' + B1*y2' + C1)  # ê²€ì¶œ ì 2
    avg_dist = (dist1 + dist2) / 2

    distance_sim = 1.0 - (avg_dist / threshold)

    return direction_sim * 0.7 + distance_sim * 0.3
```

---

### 5. í™˜ê²½ í‘œí˜„ ê°œì„  í•„ìš” ğŸ”§

**í˜„ì¬ í™˜ê²½ ë²¡í„° (6D):**
```python
# environment_independent.py:85-93
env = {
    'brightness': float(brightness_score),      # ë°ê¸°
    'contrast': float(contrast_score),          # ëŒ€ë¹„
    'edge_density': float(edge_score),          # ì—£ì§€ ë°€ë„
    'texture_complexity': float(texture_score), # í…ìŠ¤ì²˜ ë³µì¡ë„
    'blur_level': float(blur_score),            # ë¸”ëŸ¬
    'noise_level': float(noise_score)           # ë…¸ì´ì¦ˆ
}
```

**ë¬¸ì œ:**
- ì´ë¯¸ì§€ì˜ **ì˜ë¯¸ì  íŠ¹ì„±**ì„ ì¶©ë¶„íˆ ë°˜ì˜ ëª»í•¨
- ê·¸ë¦¼ì ì—¬ë¶€, ìš©ì ‘ ë¹„ë“œ ë…¸ì´ì¦ˆ ë“± ë„ë©”ì¸ íŠ¹í™” íŠ¹ì§• ì—†ìŒ

**ê°œì„  ë°©ì•ˆ:**

#### 1) CLIP ê¸°ë°˜ í™˜ê²½ íŠ¹ì§• ì¶”ê°€
```python
import torch
import clip

# CLIP ëª¨ë¸ ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

# í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
prompts = [
    "welding line with heavy shadow",
    "clear welding line without shadow",
    "noisy welding surface with beads",
    "clean welding surface"
]

def extract_clip_features(image):
    image_input = preprocess(Image.fromarray(image)).unsqueeze(0).to(device)
    text_inputs = torch.cat([clip.tokenize(p) for p in prompts]).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image_input)
        text_features = model.encode_text(text_inputs)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        similarity = (image_features @ text_features.T).softmax(dim=-1)

    return {
        'has_heavy_shadow': float(similarity[0, 0]),
        'has_clear_view': float(similarity[0, 1]),
        'has_noise': float(similarity[0, 2]),
        'is_clean': float(similarity[0, 3])
    }
```

#### 2) PSNR/SSIM ì¶”ê°€
```python
from skimage.metrics import peak_signal_noise_ratio, structural_similarity

def add_image_quality_metrics(image, reference=None):
    """
    ì´ë¯¸ì§€ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¶”ê°€

    Args:
        image: í˜„ì¬ ì´ë¯¸ì§€
        reference: ì°¸ì¡° ì´ë¯¸ì§€ (Noneì´ë©´ ì „ì²˜ë¦¬ ì „/í›„ ë¹„êµ)
    """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Gaussian blurë¥¼ ì°¸ì¡°ë¡œ ì‚¬ìš©
    if reference is None:
        reference = cv2.GaussianBlur(gray, (5, 5), 0)

    # PSNR (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    psnr = peak_signal_noise_ratio(gray, reference)
    psnr_normalized = 1.0 - np.clip(psnr / 50.0, 0, 1)  # ë‚®ìœ¼ë©´ ì–´ë ¤ì›€

    # SSIM (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)
    ssim_val = structural_similarity(gray, reference)
    ssim_score = 1.0 - ssim_val  # ë‚®ìœ¼ë©´ ì–´ë ¤ì›€

    return {
        'psnr_difficulty': float(psnr_normalized),
        'ssim_difficulty': float(ssim_score)
    }
```

**ìµœì¢… í™˜ê²½ ë²¡í„°:** 6D â†’ 12D
- ê¸°ì¡´ 6D (brightness, contrast, edge_density, texture, blur, noise)
- CLIP 4D (shadow, clear, noisy, clean)
- Quality 2D (PSNR, SSIM)

---

### 6. ì›Œí¬ìŠ¤í…Œì´ì…˜ í˜¸í™˜ì„± ë¬¸ì œ ğŸ”´

**ë¬¸ì œ:** `CRG311.pyd` (Windows ì „ìš©) â†’ Linuxì—ì„œ ì‘ë™ ì•ˆí•¨

**ì˜ì¡´ì„± í™•ì¸:**
```bash
âœ“ Python: 3.11.14
âœ“ torch: 2.6.0+cu124
âœ“ opencv: 4.12.0
âœ“ botorch: 0.16.0
âœ“ ultralytics: 8.3.227
âœ— CRG311: ModuleNotFoundError
```

**í•´ê²° ì¤‘:** AirLine ê³µì‹ ë¦¬í¬ì—ì„œ Linux ë¹Œë“œ ì„¤ì¹˜

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

### Step 1: AirLine Linux ì„¤ì¹˜
- [ ] github.com/sair-lab/AirLine clone
- [ ] README í™•ì¸ ë° ë¹Œë“œ
- [ ] `import CRG311` í…ŒìŠ¤íŠ¸

### Step 2: í‰ê°€ ë©”íŠ¸ë¦­ ë³€ê²½
- [ ] `line_equation_evaluation()` í•¨ìˆ˜ êµ¬í˜„
- [ ] `simple_line_evaluation()` ëŒ€ì²´
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### Step 3: í™˜ê²½ íŠ¹ì§• ê°•í™”
- [ ] CLIP ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸
- [ ] `extract_clip_features()` êµ¬í˜„
- [ ] PSNR/SSIM ë©”íŠ¸ë¦­ ì¶”ê°€
- [ ] `environment_independent.py` ì—…ë°ì´íŠ¸

### Step 4: RANSAC ê°€ì¤‘ì¹˜ ì¶”ê°€
- [ ] BOUNDSë¥¼ 6D â†’ 9Dë¡œ í™•ì¥
- [ ] `objective_function()`ì—ì„œ 3ê°œ íŒŒë¼ë¯¸í„° ì¶”ê°€
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### Step 5: í™˜ê²½ ë³€ìˆ˜ í†µí•©
- [ ] ì´ë¯¸ì§€ë³„ í™˜ê²½ ë²¡í„° ì¶”ì¶œ ë° ì €ì¥
- [ ] BOUNDSë¥¼ 9D â†’ 15Dë¡œ í™•ì¥
- [ ] GP ì…ë ¥ì„ (x, z)ë¡œ ë³€ê²½
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### Step 6: íŒíƒ€ì§€ ê´€ì¸¡ êµ¬í˜„
- [ ] BoRisk ë…¼ë¬¸ ì•Œê³ ë¦¬ì¦˜ ì¬í™•ì¸
- [ ] CVaR Knowledge Gradient íšë“í•¨ìˆ˜ êµ¬í˜„
- [ ] Fantasy observation êµ¬í˜„
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

---

## ğŸ“ ì‘ì—… ë¡œê·¸

### 2025.11.11 - ì´ˆê¸° ë¶„ì„

**ì™„ë£Œ:**
- âœ… ì½”ë“œ ì›Œí¬ìŠ¤í…Œì´ì…˜ ì´ì‹ ì™„ë£Œ
- âœ… Python í™˜ê²½ êµ¬ì„± (conda env: weld2024_mk2)
- âœ… ì˜ì¡´ì„± ì„¤ì¹˜: torch, opencv, botorch, ultralytics
- âœ… ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸: `../dataset/`
- âœ… 6ê°€ì§€ ì£¼ìš” ë¬¸ì œì  ë°œê²¬ ë° ë¶„ì„

**ë°œê²¬í•œ íŒŒì¼ë“¤:**
```
/home/jeongho/projects/graduate/
â”œâ”€â”€ BO_optimization/          # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ optimization.py
â”‚   â”œâ”€â”€ full_pipeline.py
â”‚   â”œâ”€â”€ environment_independent.py
â”‚   â”œâ”€â”€ models/best.pt
â”‚   â””â”€â”€ [ê¸°íƒ€ .py íŒŒì¼ë“¤]
â”œâ”€â”€ dataset/                  # ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ images/test/         # 119ì¥ ì´ë¯¸ì§€
â”‚   â””â”€â”€ ground_truth.json
â””â”€â”€ YOLO_AirLine/            # AirLine ê´€ë ¨
    â”œâ”€â”€ AirLine_assemble_test.py
    â”œâ”€â”€ CRG311.pyd           # Windows ì „ìš© (ë¬¸ì œ)
    â””â”€â”€ CRG/extractC/CRGandLP.cpp  # C++ ì†ŒìŠ¤
```

**ë‹¤ìŒ:** AirLine ê³µì‹ GitHubì—ì„œ Linux ë¹Œë“œ ì„¤ì¹˜

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** 2025.11.11 19:00
