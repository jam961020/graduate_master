# ë‹¤ìŒ ì„¸ì…˜ ì‹œì‘ ê°€ì´ë“œ

**ë‚ ì§œ**: 2025.11.11 19:35
**ì´ì „ ì„¸ì…˜**: Context 75% ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ì„¸ì…˜ ì¢…ë£Œ

---

## âš¡ ì¦‰ì‹œ í™•ì¸í•  ê²ƒ

### 1. í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸
```bash
# ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ ìƒíƒœ
ps aux | grep "python.*optimization.py"

# ë¡œê·¸ í™•ì¸
tail -50 new_test.log

# ë°˜ë³µë³„ ë¡œê·¸ í™•ì¸
ls -lh logs/
cat logs/iter_001.json
cat logs/iter_002.json

# ìµœì¢… ê²°ê³¼
ls -lh results/
cat results/bo_cvar_*.json | tail -1
```

### 2. CVaR ê°’ í™•ì¸
- **ì´ì „ í…ŒìŠ¤íŠ¸**: CVaR = 0.0011 (ë§¤ìš° ë‚®ìŒ)
- **ê¸°ëŒ€ê°’**: CVaR > 0.01 (í‰ê°€ ë©”íŠ¸ë¦­ ê°œì„ ìœ¼ë¡œ)
- **ì„±ê³µ ê¸°ì¤€**: ì´ì „ ëŒ€ë¹„ 10ë°° ì´ìƒ ê°œì„ 

---

## ğŸ”´ **ìµœìš°ì„  ì‘ì—…: CVaR ê³„ì‚° ë°©ì‹ ìˆ˜ì •**

### ë¬¸ì œì  (CRITICAL!)
í˜„ì¬ ì½”ë“œëŠ” **BoRisk ì•Œê³ ë¦¬ì¦˜ê³¼ ì™„ì „íˆ ë‹¤ë¦„**:

**í˜„ì¬ ì˜ëª»ëœ êµ¬í˜„**:
```python
# optimization.py:217-273
def objective_function(X, images_data, yolo_detector, alpha=0.3):
    # ë¬¸ì œ 1: ë§¤ë²ˆ ëª¨ë“  ì´ë¯¸ì§€(113ê°œ) í‰ê°€ â†’ ë§¤ìš° ëŠë¦¼!
    scores = []
    for img_data in images_data:
        score = line_equation_evaluation(...)
        scores.append(score)

    # ë¬¸ì œ 2: ì§ì ‘ CVaR ê³„ì‚° (GP ì‚¬ìš© ì•ˆ í•¨)
    cvar = np.mean(np.sort(scores)[:n_worst])
    return cvar
```

**BoRisk ì˜¬ë°”ë¥¸ ë°©ì‹** (BoTorch íŠœí† ë¦¬ì–¼ ê¸°ë°˜):
```python
# 1. í™˜ê²½ ë³€ìˆ˜ ì²˜ë¦¬
# - ê° ì´ë¯¸ì§€ = í™˜ê²½ w
# - w_setì—ì„œ n_wê°œ ìƒ˜í”Œë§ (ì˜ˆ: 10ê°œ)
w_set = sample_images(images_data, n_w=10)

# 2. GP ëª¨ë¸: (x, w) â†’ y
model = SingleTaskGP(
    train_X,  # [N, 9+6] = params 9D + env 6D
    train_Y,
    input_transform=AppendFeatures(feature_set=w_set)
)

# 3. íšë“ í•¨ìˆ˜: qMultiFidelityKnowledgeGradient + CVaR
acqf = qMultiFidelityKnowledgeGradient(
    model=model,
    num_fantasies=NUM_FANTASIES,
    objective=CVaR(alpha=0.3, n_w=n_w)
)

# 4. ë§¤ iteration:
#    - í•˜ë‚˜ì˜ x ì„ íƒ
#    - w_setì˜ ëª‡ ê°œ ì´ë¯¸ì§€ë§Œ í‰ê°€ (10ê°œ, 113ê°œ ì•„ë‹˜!)
#    - GP ì—…ë°ì´íŠ¸
candidate = optimize_acqf(acqf, bounds)
observations = evaluate_on_w_samples(candidate, w_set)  # 10ê°œë§Œ!
```

### BoRisk ë…¼ë¬¸ì—ì„œ ìš”êµ¬í•˜ëŠ” ë°©ì‹
**GPë¥¼ í™œìš©í•œ CVaR ê³„ì‚°**:
```python
# TODO: optimization.pyì— ì¶”ê°€ í•„ìš”
def compute_cvar_from_gp(gp, X, images_data, alpha=0.3, n_samples=1000):
    """
    GP ì˜ˆì¸¡ ë¶„í¬ì—ì„œ CVaR ê³„ì‚°

    Args:
        gp: í•™ìŠµëœ Gaussian Process
        X: íŒŒë¼ë¯¸í„° [1, 9]
        images_data: ì´ë¯¸ì§€ ë°ì´í„° (í™˜ê²½ z ì¶”ì¶œìš©)
        alpha: CVaR threshold (worst Î±%)
        n_samples: ëª¬í…Œì¹´ë¥¼ë¡œ ìƒ˜í”Œ ê°œìˆ˜

    Returns:
        cvar: float
    """
    # 1. ê° ì´ë¯¸ì§€ì— ëŒ€í•´ í™˜ê²½ ë²¡í„° ì¶”ì¶œ
    env_features = []
    for img_data in images_data:
        z = extract_environment(img_data['image'])  # 6D
        env_features.append(z)

    # 2. GP ì…ë ¥: [x, z]
    X_with_env = []
    for z in env_features:
        x_z = torch.cat([X, torch.tensor([z])], dim=-1)  # [1, 15]
        X_with_env.append(x_z)

    X_batch = torch.cat(X_with_env, dim=0)  # [N_images, 15]

    # 3. GPë¡œë¶€í„° ì˜ˆì¸¡ ë¶„í¬ ìƒ˜í”Œë§
    with torch.no_grad():
        posterior = gp.posterior(X_batch)
        samples = posterior.rsample(torch.Size([n_samples]))  # [n_samples, N_images]

    # 4. ê° ìƒ˜í”Œì— ëŒ€í•´ CVaR ê³„ì‚°
    cvars = []
    for i in range(n_samples):
        sample_scores = samples[i]  # [N_images]
        n_worst = max(1, int(len(sample_scores) * alpha))
        worst = torch.topk(sample_scores, n_worst, largest=False).values
        cvars.append(worst.mean().item())

    # 5. í‰ê·  CVaR ë°˜í™˜
    return np.mean(cvars)
```

### ìˆ˜ì • ê³„íš (BoRisk ì •ì‹ ì•Œê³ ë¦¬ì¦˜)

#### Step 1: í™˜ê²½ ë³€ìˆ˜ ì¶”ì¶œ ë° w_set êµ¬ì„±
```python
from environment_independent import extract_environment

# ëª¨ë“  ì´ë¯¸ì§€ì˜ í™˜ê²½ ë²¡í„° ë¯¸ë¦¬ ì¶”ì¶œ
all_env_features = []
for img_data in images_data:
    env = extract_environment(img_data['image'])  # 6D
    all_env_features.append(torch.tensor([
        env['brightness'], env['contrast'], env['edge_density'],
        env['texture_complexity'], env['blur_level'], env['noise_level']
    ]))

# w_set: ë§¤ iterationë§ˆë‹¤ n_wê°œ ìƒ˜í”Œë§ (ì˜ˆ: 10~20ê°œ)
def sample_w_set(all_env_features, n_w=15):
    indices = torch.randperm(len(all_env_features))[:n_w]
    return torch.stack([all_env_features[i] for i in indices])
```

#### Step 2: GP ëª¨ë¸ êµ¬ì¡° ë³€ê²½
```python
from botorch.models import SingleTaskGP
from botorch.models.transforms.input import AppendFeatures

# GP ì…ë ¥: [N, 9] params only
# AppendFeaturesê°€ ìë™ìœ¼ë¡œ w_set ì¶”ê°€ â†’ [N*n_w, 15]
model = SingleTaskGP(
    train_X,  # [N, 9] paramsë§Œ
    train_Y,  # [N*n_w, 1] ê° xë§ˆë‹¤ n_wê°œ í™˜ê²½ í‰ê°€
    input_transform=AppendFeatures(feature_set=w_set)
)
```

#### Step 3: íšë“ í•¨ìˆ˜ë¥¼ BoRiskë¡œ ë³€ê²½
```python
from botorch.acquisition.multi_fidelity import qMultiFidelityKnowledgeGradient
from botorch.acquisition.objective import GenericMCObjective

def cvar_objective(samples, alpha=0.3):
    """CVaR ê³„ì‚° objective"""
    # samples: [n_samples, n_w, 1]
    n_worst = max(1, int(samples.shape[1] * alpha))
    worst_samples = torch.topk(samples, n_worst, dim=1, largest=False).values
    return worst_samples.mean(dim=1)

# BoRisk íšë“ í•¨ìˆ˜
acqf = qMultiFidelityKnowledgeGradient(
    model=model,
    num_fantasies=64,  # íŒíƒ€ì§€ ìƒ˜í”Œ ê°œìˆ˜
    objective=GenericMCObjective(cvar_objective),
    project=lambda X: X[..., :9]  # w ì œê±°, xë§Œ ë°˜í™˜
)
```

#### Step 4: í‰ê°€ ë°©ì‹ ë³€ê²½
```python
# ê¸°ì¡´ (ì˜ëª»ë¨): ëª¨ë“  113ê°œ ì´ë¯¸ì§€ í‰ê°€
# ìƒˆ ë°©ì‹: w_setì˜ n_wê°œë§Œ í‰ê°€

def evaluate_on_w_set(params, images_data, env_features, w_set_indices):
    """
    í•˜ë‚˜ì˜ paramsì— ëŒ€í•´ w_set ì´ë¯¸ì§€ë§Œ í‰ê°€

    Args:
        params: [9D] íŒŒë¼ë¯¸í„°
        images_data: ì „ì²´ ì´ë¯¸ì§€ ë°ì´í„°
        env_features: ì „ì²´ í™˜ê²½ ë²¡í„° ë¦¬ìŠ¤íŠ¸
        w_set_indices: w_setì— ì„ íƒëœ ì´ë¯¸ì§€ ì¸ë±ìŠ¤

    Returns:
        scores: [n_w, 1] ê° í™˜ê²½ì—ì„œì˜ ì„±ëŠ¥
    """
    scores = []
    for idx in w_set_indices:
        img_data = images_data[idx]
        score = evaluate_single(params, img_data)
        scores.append(score)

    return torch.tensor(scores).unsqueeze(-1)

# ë§¤ iteration:
candidate = optimize_acqf(acqf, bounds, q=1)
observations = evaluate_on_w_set(candidate, images_data, all_env, w_indices)
# observations: [n_w, 1] - w_set í¬ê¸°ë§Œí¼ë§Œ í‰ê°€!
```

#### Step 5: BO ë£¨í”„ ìˆ˜ì •
```python
for iteration in range(n_iterations):
    # 1. w_set ìƒ˜í”Œë§ (ë§¤ë²ˆ ìƒˆë¡œ ë˜ëŠ” ê³ ì •)
    w_set, w_indices = sample_w_set(all_env_features, n_w=15)

    # 2. GP ëª¨ë¸ ìƒì„±/ì—…ë°ì´íŠ¸
    model = SingleTaskGP(
        train_X,  # [N, 9]
        train_Y,  # [N*n_w, 1]
        input_transform=AppendFeatures(feature_set=w_set)
    )
    fit_gpytorch_mll(mll)

    # 3. íšë“ í•¨ìˆ˜ ìƒì„±
    acqf = qMultiFidelityKnowledgeGradient(...)

    # 4. ë‹¤ìŒ í‰ê°€ ì§€ì  ì„ íƒ
    candidate, _ = optimize_acqf(acqf, bounds, q=1)

    # 5. w_setì—ì„œë§Œ í‰ê°€ (15ê°œë§Œ!)
    new_Y = evaluate_on_w_set(candidate, images_data, all_env, w_indices)

    # 6. ë°ì´í„° ì¶”ê°€
    train_X = torch.cat([train_X, candidate])
    train_Y = torch.cat([train_Y, new_Y])
```

### í•µì‹¬ ì°¨ì´ì  ìš”ì•½

| í•­ëª© | í˜„ì¬ (ì˜ëª»ë¨) | BoRisk (ì˜¬ë°”ë¦„) |
|------|--------------|----------------|
| **í‰ê°€ ê°œìˆ˜** | ë§¤ë²ˆ 113ê°œ ì „ì²´ | ë§¤ë²ˆ n_wê°œ (10~20ê°œ) |
| **GP ëª¨ë¸** | (x) â†’ y | (x, w) â†’ y |
| **íšë“ í•¨ìˆ˜** | EI/UCB | ÏKG (qMFKG) |
| **CVaR ê³„ì‚°** | ì§ì ‘ í‰ê°€ | GP ìƒ˜í”Œë§ |
| **ì†ë„** | ë§¤ìš° ëŠë¦¼ | ë¹ ë¦„ (1/10) |

---

## ğŸ“‹ ì™„ë£Œëœ ì‘ì—… ìš”ì•½

### 1. í‰ê°€ ë©”íŠ¸ë¦­ ë³€ê²½ âœ…
- **íŒŒì¼**: `optimization.py:39-116`
- **í•¨ìˆ˜**: `line_equation_evaluation()`
- **ë°©ì‹**: ì§ì„  ë°©ì •ì‹ Ax + By + C = 0 ê¸°ë°˜
- **í‰ê°€ ì§€í‘œ**:
  - ë°©í–¥ ìœ ì‚¬ë„: ë²•ì„  ë²¡í„° ë‚´ì  (60% ê°€ì¤‘ì¹˜)
  - í‰í–‰ ê±°ë¦¬: GT ì¤‘ì ì—ì„œ ê²€ì¶œ ì§ì„ ê¹Œì§€ (40% ê°€ì¤‘ì¹˜)

### 2. RANSAC ê°€ì¤‘ì¹˜ ìµœì í™” âœ…
- **ì°¨ì› í™•ì¥**: 6D â†’ 9D
- **ìƒˆ íŒŒë¼ë¯¸í„°**:
  - `ransac_center_w`: [0.0, 1.0]
  - `ransac_length_w`: [0.0, 1.0]
  - `ransac_consensus_w`: [1, 10] (ì •ìˆ˜)
- **ìˆ˜ì • ìœ„ì¹˜**:
  - `optimization.py:33-36` - BOUNDS
  - `optimization.py:296` - Sobol dimension
  - `optimization.py:238-240` - params ë”•ì…”ë„ˆë¦¬
  - `optimization.py:539-541` - ê²°ê³¼ ì €ì¥

### 3. ë¡œê¹… ìµœì í™” âœ…
- **í™”ë©´ ì¶œë ¥**: ìµœì†Œí™” (í† í° ì ˆì•½)
- **íŒŒì¼ ì €ì¥**: `logs/iter_XXX.json`
- **í¬í•¨ ë‚´ìš©**:
  - iteration, acq_function, acq_value
  - parameters (9D ì „ì²´)
  - cvar, cvar_normalized

---

## ğŸ”§ ë‚¨ì€ ì‘ì—… ìš°ì„ ìˆœìœ„

### Priority 1: CVaR ê³„ì‚° ë°©ì‹ ìˆ˜ì • (Critical)
- [ ] GP ê¸°ë°˜ CVaR ê³„ì‚° í•¨ìˆ˜ êµ¬í˜„
- [ ] objective_functionì„ evaluate_realë¡œ ë¶„ë¦¬
- [ ] íšë“í•¨ìˆ˜ í‰ê°€ ì‹œ GP ê¸°ë°˜ CVaR ì‚¬ìš©
- [ ] ì´ˆê¸°í™” ë‹¨ê³„ë§Œ ì§ì ‘ í‰ê°€ ì‚¬ìš©

### Priority 2: í™˜ê²½ ë³€ìˆ˜ í†µí•© (Critical)
- [ ] 9D â†’ 15D í™•ì¥ (params 9D + env 6D)
- [ ] `extract_environment()` í•¨ìˆ˜ í†µí•©
- [ ] GP ì…ë ¥: (x, z) â†’ y
- [ ] ìƒˆë¡œìš´ ì´ë¯¸ì§€ z*ì—ì„œ ìµœì  x* ì˜ˆì¸¡

### Priority 3: íŒíƒ€ì§€ ê´€ì¸¡ êµ¬í˜„ (High)
- [ ] CVaR Knowledge Gradient íšë“í•¨ìˆ˜
- [ ] í™˜ê²½ ì¡°ê±´ë¶€ ì˜ˆì¸¡
- [ ] ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í‰ê°€

### Priority 4: í™˜ê²½ íŠ¹ì§• ê°•í™” (Medium)
- [ ] CLIP ê¸°ë°˜ shadow/noise íƒì§€
- [ ] PSNR/SSIM ì¶”ê°€
- [ ] 6D â†’ 9D ë˜ëŠ” 10D í™•ì¥

---

## ğŸ“ ì¤‘ìš” ì°¸ê³ ì‚¬í•­

### ëŒ€ì „ì œ (ì ˆëŒ€ ìŠì§€ ë§ ê²ƒ)
1. **í•˜ë“œì½”ë”©ìœ¼ë¡œ ìš°íšŒí•˜ì§€ ë§ê³  ë¬¸ì œì˜ ë³¸ì§ˆì„ í•´ê²°í•˜ë¼**
2. **ì„ì‹œ í•´ê²°ì±… ì‚¬ìš© ì‹œ ë°˜ë“œì‹œ TODO ì£¼ì„ì„ ë‚¨ê²¨ë¼**

### í˜„ì¬ ì½”ë“œì˜ ì„ì‹œ í•´ê²°ì±…
```python
# optimization.py:217 - TODO: GP ê¸°ë°˜ CVaRë¡œ ë³€ê²½ í•„ìš”
def objective_function(X, images_data, yolo_detector, alpha=0.3):
    # í˜„ì¬: ì§ì ‘ í‰ê°€ (ì„ì‹œ)
    # í•„ìš”: GP ìƒ˜í”Œë§ ê¸°ë°˜ CVaR
    pass
```

### í•µì‹¬ íŒŒì¼ ìœ„ì¹˜
- **ë©”ì¸ ë¡œì§**: `optimization.py` (551 lines)
- **íŒŒì´í”„ë¼ì¸**: `full_pipeline.py` (YOLO + AirLine)
- **í™˜ê²½ ì¶”ì¶œ**: `environment_independent.py` (6D ë²¡í„°)
- **í‰ê°€ í•¨ìˆ˜**: `optimization.py:39-116` (line_equation_evaluation)
- **ì‘ì—… ë¡œê·¸**: `TRACKING.md` (ìƒì„¸ ì§„í–‰ ìƒí™©)

### ì‹¤í–‰ ëª…ë ¹
```bash
# í˜„ì¬ í…ŒìŠ¤íŠ¸ (ì§„í–‰ ì¤‘)
python optimization.py --iterations 2 --n_initial 3 --alpha 0.3

# ë‹¤ìŒ ì‹¤í—˜ (ì„±ê³µ ì‹œ)
python optimization.py --iterations 20 --n_initial 10 --alpha 0.3

# ì „ì²´ ì‹¤í—˜
python optimization.py --iterations 30 --n_initial 15 --alpha 0.2
```

---

## ğŸ” ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ í™•ì¸:
- [ ] `logs/` ë””ë ‰í† ë¦¬ì— iter_*.json íŒŒì¼ ìƒì„±ë˜ì—ˆëŠ”ê°€?
- [ ] CVaR ê°’ì´ 0ì´ ì•„ë‹Œê°€? (0ì´ë©´ í‰ê°€ ì‹¤íŒ¨)
- [ ] RANSAC íŒŒë¼ë¯¸í„°ê°€ ì œëŒ€ë¡œ ì „ë‹¬ë˜ëŠ”ê°€?
- [ ] ì§ì„  ë°©ì •ì‹ í‰ê°€ê°€ ì˜¬ë°”ë¥¸ê°€?
- [ ] GP í•™ìŠµì´ ì‹¤íŒ¨í•˜ì§€ ì•Šì•˜ëŠ”ê°€?

---

**ë‹¤ìŒ ì„¸ì…˜ ì‹œì‘ ì‹œ ì´ íŒŒì¼ì„ ë¨¼ì € ì½ìœ¼ì„¸ìš”!**
